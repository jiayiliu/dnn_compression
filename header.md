<!-- https://github.hubspot.com/sortable/ -->
<script src="js/sortable.min.js"></script>
<link rel="stylesheet" href="css/sortable-theme-bootstrap.css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128364527-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128364527-3');
</script>


# Model Compression

This is a collection for model compression and acceleartion for DNNs, with a bias towards to the CV domain.

## Existing collections

### Repo

+ [Knowledge Distillation](https://github.com/dkozlov/awesome-knowledge-distillation)
+ [Model Compression Acceleration](https://github.com/jnjaby/Model-Compression-Acceleration)
### Survey paper

+ [Recent Advances in Efficient Computation of Deep Convolutional Neural Networks](https://arxiv.org/pdf/1802.00939.pdf)
+ [A Survey on Methods and Theories of Quantized Neural Networks](https://arxiv.org/pdf/1808.04752.pdf)


## Tools

+ [PocketFlow](https://pocketflow.github.io)
+ [Distiller](https://nervanasystems.github.io/distiller/)
+ [Tensorflow Lite](https://www.tensorflow.org/lite)
+ [Tensorflow Model Optimization](https://www.tensorflow.org/model_optimization)
+ [TVM](https://tvm.ai/)


## Literature Summry

List:

